{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-06T18:58:33.032587Z",
     "start_time": "2026-01-06T18:58:33.016683Z"
    }
   },
   "source": [
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import textgrad as tg"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T18:51:28.707074Z",
     "start_time": "2026-01-06T18:51:28.685840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed) :\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ],
   "id": "7d4f16cde6077034",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from textgrad.engine_experimental.litellm import LiteLLMEngine\n",
    "\n",
    "LiteLLMEngine(\"groq/openai/gpt-oss-120b\" , cache=True).generate(content=\"hello, what's 3+4\" , system_prompt=\"you are an assistant\")"
   ],
   "id": "474a25c1a814f09c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:50:05.105569Z",
     "start_time": "2026-01-06T19:50:05.058532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from textgrad.engine.local_model_openai_api import ChatExternalClient\n",
    "\n",
    "# start a server with lm-studio and point it to the right address; here we use the default address.\n",
    "client = OpenAI(base_url=\"https://api.groq.com/openai/v1\" , api_key=\"\")\n",
    "\n",
    "engine = ChatExternalClient(client=client , model_string='openai/gpt-oss-120b')"
   ],
   "id": "8614f2f1e1548508",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:50:05.819148Z",
     "start_time": "2026-01-06T19:50:05.805286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tg.set_backward_engine(engine , override=True)\n",
    "\n",
    "initial_solution = \"\"\"To solve the equation 3x^2 - 7x + 2 = 0, we use the quadratic formula:\n",
    "x = (-b Â± âˆš(b^2 - 4ac)) / 2a\n",
    "a = 3, b = -7, c = 2\n",
    "x = (7 Â± âˆš((-7)^2 + 4(3)(2))) / 6\n",
    "x = (7 Â± âˆš73) / 6\n",
    "The solutions are:\n",
    "x1 = (7 + âˆš73)\n",
    "x2 = (7 - âˆš73)\"\"\"\n",
    "\n",
    "solution = tg.Variable(initial_solution ,\n",
    "                       requires_grad=True ,\n",
    "                       role_description=\"solution to the math question\")\n",
    "\n",
    "loss_system_prompt = tg.Variable(\"\"\"You will evaluate a solution to a math question.\n",
    "Do not attempt to solve it yourself, do not give a solution, only identify errors. Be super concise.\"\"\" ,\n",
    "                                 requires_grad=False ,\n",
    "                                 role_description=\"system prompt\")\n",
    "\n",
    "loss_fn = tg.TextLoss(loss_system_prompt)\n",
    "optimizer = tg.TGD([ solution ])"
   ],
   "id": "71634f6273781ad8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:50:08.317299Z",
     "start_time": "2026-01-06T19:50:06.599586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = loss_fn(solution)\n",
    "print(loss.value)"
   ],
   "id": "ebc023ec74fa4df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The discriminant should be \\(b^{2}-4ac = (-7)^{2}-4\\cdot3\\cdot2 = 49-24 = 25\\), not \\(49+24 = 73\\).  \n",
      "- The denominator \\(2a = 6\\) must be kept in the final expressions; the solutions are \\(\\displaystyle x=\\frac{7\\pm5}{6}\\), i.e. \\(x=2\\) and \\(x=\\frac13\\).  \n",
      "- As written, the answers \\((7\\pm\\sqrt{73})\\) omit the division byâ€¯6 and use the wrong discriminant.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:06:02.059869Z",
     "start_time": "2026-01-06T19:06:02.025817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print textgrad.engine info\n",
    "print(tg.engine.info( ))"
   ],
   "id": "1f166a0897787e19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine model: mlabonne/NeuralBeagle14-7B-GGUF\n",
      "Engine instance: <textgrad.engine.local_model_openai_api.ChatExternalClient object at 0x110a423c0>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:17:01.750208Z",
     "start_time": "2026-01-06T19:17:01.739238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# env variable\n",
    "os.environ[ 'GROQ_API_KEY' ] = \"\""
   ],
   "id": "6eb4c679c5fdbc27",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:18:40.935576Z",
     "start_time": "2026-01-06T19:18:40.318906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from litellm import completion\n",
    "\n",
    "response = completion(\n",
    "        model=\"groq/openai/gpt-oss-120b\" ,\n",
    "        messages=[\n",
    "                { \"role\" : \"user\" , \"content\" : \"hello from litellm\" }\n",
    "        ] ,\n",
    ")\n",
    "print(response)"
   ],
   "id": "9f86a316fbc8f6d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-04017b6a-6a30-4d40-8141-8d3aa9151b44', created=1767727120, model='openai/gpt-oss-120b', object='chat.completion', system_fingerprint='fp_fe269835c7', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hello! ðŸ‘‹ How can I assist you today?', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None, reasoning='We need to respond. The user says \"hello from litellm\". Probably a greeting. Should respond friendly.'))], usage=Usage(completion_tokens=44, prompt_tokens=76, total_tokens=120, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=24, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None, queue_time=0.044147329, prompt_time=0.003207882, completion_time=0.092844607, total_time=0.096052489), usage_breakdown=None, x_groq={'id': 'req_01keabygb4f05bfcyf935qxqaf', 'seed': 565054761}, service_tier='auto')\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T19:20:41.075023Z",
     "start_time": "2026-01-06T19:20:40.390273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from textgrad.engine_experimental.litellm import LiteLLMEngine\n",
    "\n",
    "LiteLLMEngine(\"groq/openai/gpt-oss-120b\" , cache=True).generate(content=\"hello, what's 3+4\" , system_prompt=\"you are an assistant\")"
   ],
   "id": "f5448c7d7d43d3b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!\\u202fThe sum of\\u202f3\\u202fand\\u202f4\\u202fis\\u202f7.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c5d05022ebd784c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
