{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-09T15:51:19.945430Z",
     "start_time": "2026-01-09T15:51:19.912746Z"
    }
   },
   "source": [
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import textgrad as tg"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T10:12:16.557376Z",
     "start_time": "2026-01-09T10:12:16.536075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed) :\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ],
   "id": "7d4f16cde6077034",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T10:12:16.583316Z",
     "start_time": "2026-01-09T10:12:16.560037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from textgrad.engine.local_model_openai_api import ChatExternalClient\n",
    "\n",
    "# start a server with lm-studio and point it to the right address; here we use the default address.\n",
    "client = OpenAI(base_url=\"http://localhost:11434/v1/\" , api_key=\"ollama\")\n",
    "\n",
    "engine = ChatExternalClient(client=client , model_string='zongwei/gemma3-translator:1b')"
   ],
   "id": "8614f2f1e1548508",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T10:12:16.850430Z",
     "start_time": "2026-01-09T10:12:16.834279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tg.set_backward_engine(engine , override=True)\n",
    "\n",
    "initial_solution = \"\"\"Hello, how are you?\"\"\"\n",
    "\n",
    "solution = tg.Variable(initial_solution ,\n",
    "                       requires_grad=True ,\n",
    "                       role_description=\"Translate this sentence to French\")\n",
    "\n",
    "loss_system_prompt = tg.Variable(\"\"\"You will evaluate a solution to a math question.\n",
    "Do not attempt to solve it yourself, do not give a solution, only identify errors. Be super concise.\"\"\" ,\n",
    "                                 requires_grad=False ,\n",
    "                                 role_description=\"system prompt\")\n",
    "\n",
    "loss_fn = tg.TextLoss(loss_system_prompt)\n",
    "optimizer = tg.TGD([ solution ])"
   ],
   "id": "71634f6273781ad8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T10:12:20.411912Z",
     "start_time": "2026-01-09T10:12:18.681290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = loss_fn(solution)\n",
    "print(loss.value)"
   ],
   "id": "ebc023ec74fa4df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thank you for asking!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T10:13:10.960503Z",
     "start_time": "2026-01-09T10:13:06.189897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss.backward( )\n",
    "optimizer.step( )\n",
    "print(solution.value)"
   ],
   "id": "1ca9a42676359b83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, comment allez-vous?\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T15:31:20.603781Z",
     "start_time": "2026-01-09T15:31:12.872016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"aimped/medical-translation-test-set\")"
   ],
   "id": "c5d05022ebd784c1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T15:31:42.509880Z",
     "start_time": "2026-01-09T15:31:42.473351Z"
    }
   },
   "cell_type": "code",
   "source": "ds[ \"en_fr\" ]",
   "id": "c70677657279f71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target'],\n",
       "    num_rows: 1049\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T15:49:08.589388Z",
     "start_time": "2026-01-09T15:49:08.556742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split into train_set, val_set, test_set\n",
    "train_size = int(0.8 * len(ds[ \"en_fr\" ]))\n",
    "val_size = int(0.1 * len(ds[ \"en_fr\" ]))\n",
    "test_size = len(ds[ \"en_fr\" ]) - train_size - val_size\n",
    "train_set = ds[ \"en_fr\" ].select(range(0 , train_size))\n",
    "val_set = ds[ \"en_fr\" ].select(range(train_size , train_size + val_size))\n",
    "test_set = ds[ \"en_fr\" ].select(range(train_size + val_size , len(ds[ \"en_fr\" ])))"
   ],
   "id": "c9661a62a6c5626c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c9c57359e23a9c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T15:49:33.928753Z",
     "start_time": "2026-01-09T15:49:33.866967Z"
    }
   },
   "cell_type": "code",
   "source": "test_set[ \"source\" ]",
   "id": "4f457d3c7a27253d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column(['A method as claimed in Claim 1, wherein the inhibitor added is selected from human α 1 -antitrypsin, human serum or plasma containing human α 1 -antitrypsin, animal serum or plasma containing a substance which can combine with free elastase in such a way that human α 1 -antitrypsin combines therewith to inhibit elastase activity, and a synthetic material containing a substance which can combine with free elastase in such a way that human α 1 -antitrypsin combines therewith to inhibit elastase activity.', 'This invention provides oligonucleotide agents that modulate an immune response by stimulating IFN production and methods of using such agents for therapeutic treatments of mammals.', 'Tel: +386 (0)1 580 00 10 Slovenská republika Eli Lilly Slovakia, s. r. o.', 'A nanoparticle according to claim 18, wherein the osteotropic gene or gene segment is selected from bone morphogenic proteins (BMP2 and 4 and others), transforming growth factor, such as TGF-β1-3, activin, phosphoproteins, osteonectin, osteopontin, bone sialoprotein, osteocalcin, vitamin-k dependent proteins, glycoproteins, and collagen (at least I and II).', 'Thus, our conclusion is that the agonist/antagonist balance would have a protective role of the joint stability; the occurrence of a muscle agonist / antagonist imbalance may be secondary to an anatomical lesion and mark the sign of its long and/or pejorative evolution', ...])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T16:22:33.773796Z",
     "start_time": "2026-01-09T16:22:33.713108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import textgrad as tg\n",
    "\n",
    "# 1. Set the TextGrad backend engine (for generating gradients)\n",
    "# Ensure you have your API key set for OpenAI or your chosen provider\n",
    "tg.set_backward_engine(engine , override=True)\n",
    "\n",
    "# 2. Define Variables\n",
    "# Source Text (English)\n",
    "source_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Initial Translation (French)\n",
    "# Note: This translation is intentionally imperfect to demonstrate optimization.\n",
    "# \"au-dessus le\" is a grammatical error; it should be \"au-dessus du\".\n",
    "initial_translation = \"Le renard brun rapide saute par-dessus du chien paresseux.\"\n",
    "\n",
    "# Reference Translations (French)\n",
    "# These are \"Gold Standard\" translations for comparison.\n",
    "reference_translations = [\n",
    "        \"Le vif renard brun saute par-dessus le chien paresseux.\"\n",
    "]\n",
    "\n",
    "# Wrap text in TextGrad Variables\n",
    "source = tg.Variable(source_text , requires_grad=False , role_description=\"source text in English\")\n",
    "translation = tg.Variable(initial_translation , requires_grad=True , role_description=\"French translation to optimize\")\n",
    "\n",
    "# Wrap references in Variables so they can be passed around easily\n",
    "ref_vars = [ tg.Variable(ref , requires_grad=False , role_description=\"reference French translation\") for ref in reference_translations ]\n",
    "\n",
    "\n",
    "# 3. Define Custom BLEU Loss Function\n",
    "def calculate_bleu_loss(prediction , ground_truth) :\n",
    "    \"\"\"\n",
    "    Calculates the BLEU score between the candidate translation (prediction)\n",
    "    and reference translations (ground_truth).\n",
    "    Returns a TextGrad Variable representing the negative BLEU score.\n",
    "    \"\"\"\n",
    "    # sacrebleu.corpus_bleu expects:\n",
    "    # sys_stream: a list of hypothesis strings (candidate translations)\n",
    "    # ref_streams: a list of lists of reference strings\n",
    "\n",
    "    # We pass a list of 1 string because we are processing one sentence at a time here\n",
    "    hypothesis_list = [ prediction.value ]\n",
    "\n",
    "    # Extract the string values from the reference Variables\n",
    "    # The inner list represents the multiple references for the single sentence\n",
    "    references_list = [ [ ref.value for ref in ground_truth ] ]\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    # sacrebleu automatically handles French tokenization (lowercasing, splitting \"l'animal\", etc.)\n",
    "    bleu = sacrebleu.corpus_bleu(hypothesis_list , references_list)\n",
    "    bleu_score = bleu.score\n",
    "\n",
    "    # Return NEGATIVE BLEU score because TextGrad minimizes loss\n",
    "    return tg.Variable(str(-bleu_score) , requires_grad=True , role_description=\"negative BLEU score\")\n",
    "\n",
    "\n",
    "# 4. Define Optimizer\n",
    "# We optimize the 'translation' variable\n",
    "optimizer = tg.TGD(parameters=[ translation ])\n",
    "\n",
    "# 5. Optimization Loop\n",
    "print(f\"Source: {source.value}\")\n",
    "print(f\"Initial Translation: {translation.value}\\n\")\n",
    "\n",
    "for i in range(3) :\n",
    "    # --- Step 1: Evaluate ---\n",
    "    # Calculate loss using our custom function\n",
    "    loss = calculate_bleu_loss(translation , ref_vars)\n",
    "\n",
    "    print(f\"--- Iteration {i + 1} ---\")\n",
    "    # Print the actual BLEU score (negate the loss value to get it back to positive)\n",
    "    print(f\"Current BLEU Score: {-float(loss.value):.2f}\")\n",
    "\n",
    "    # --- Step 2: Backward Pass ---\n",
    "    # Generate textual gradients based on the loss\n",
    "    loss.backward( )\n",
    "\n",
    "    # --- Step 3: Update ---\n",
    "    # Update the translation variable based on the gradients\n",
    "    optimizer.step( )\n",
    "\n",
    "    print(f\"Updated Translation: {translation.value}\\n\")\n",
    "\n",
    "print(\"Optimization Complete.\")"
   ],
   "id": "82afb8c3f4625d9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The quick brown fox jumps over the lazy dog.\n",
      "Initial Translation: Le renard brun rapide saute par-dessus du chien paresseux.\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Current BLEU Score: 23.74\n",
      "Updated Translation: Le renard brun rapide saute par-dessus du chien paresseux.\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Current BLEU Score: 23.74\n",
      "Updated Translation: Le renard brun rapide saute par-dessus du chien paresseux.\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Current BLEU Score: 23.74\n",
      "Updated Translation: Le renard brun rapide saute par-dessus du chien paresseux.\n",
      "\n",
      "Optimization Complete.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:03:44.006738Z",
     "start_time": "2026-01-09T17:03:43.962032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_sample(x , y , model) :\n",
    "    \"\"\"\n",
    "    This function allows us to evaluate if an answer to a question in the prompt is a good answer.\n",
    "\n",
    "    \"\"\"\n",
    "    x = tg.Variable(x , requires_grad=False , role_description=\"query to the language model\")\n",
    "\n",
    "    references_list = [ y ]\n",
    "    y = tg.Variable(y , requires_grad=False , role_description=\"correct answer for the query\")\n",
    "    response = model(x)\n",
    "\n",
    "    hypothesis_list = [ response.value ]\n",
    "    print(\"Hypothesis: \" , response)\n",
    "    # Calculate BLEU score\n",
    "    # sacrebleu automatically handles French tokenization (lowercasing, splitting \"l'animal\", etc.)\n",
    "    bleu = sacrebleu.corpus_bleu(hypothesis_list , references_list)\n",
    "    bleu_score = bleu.score\n",
    "    return tg.Variable(str(-bleu_score) , requires_grad=True , role_description=\"negative BLEU score\")"
   ],
   "id": "f1127441d9e7f236",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:03:45.230707Z",
     "start_time": "2026-01-09T17:03:45.116148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test on a sample from the test set\n",
    "sample = test_set[ 0 ]\n",
    "x = \"Translate this sentence to French: \" + sample[ \"source\" ]\n",
    "y = sample[ \"target\" ]\n",
    "\n",
    "system_prompt = tg.Variable(\"Translate this sentence to French.\" ,\n",
    "                            requires_grad=True ,\n",
    "                            role_description=\"system prompt to the language model\")\n",
    "model = tg.BlackboxLLM(engine , system_prompt)\n",
    "eval_sample(x , y , model)"
   ],
   "id": "8084ed009d548523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis:  Here’s a translation of the sentence into French, aiming for accuracy and a slightly formal tone suitable for a scientific document:\n",
      "\n",
      "“Un procédé comme décrit dans la revendication 1, dans lequel l'inhibiteur ajouté est sélectionné à partir d'alpha-1-antitrypsin humain, serum ou plasma contenant de l'alpha-1-antitrypsin humain, serum ou plasma contenant une substance qui combine avec l'elastase d'une manière telle que l'alpha-1-antitrypsin combine avec elle à inhiber l'activité de l'elastase, et un matériau synthétique contenant une substance qui combine avec l'elastase d'une manière telle que l'alpha-1-antitrypsin combine avec elle à inhiber l'activité de l'elastase.”\n",
      "\n",
      "Here's a breakdown of why I chose these words:\n",
      "\n",
      "*   **“Un procédé comme décrit dans la revendication 1”** - \"A method as described in Claim 1\" - This is a standard and accurate way to introduce the subject.\n",
      "*   **“dans lequel”** - \"wherein\" -  A more formal way to introduce the concept.\n",
      "*   **“l'inhibiteur ajouté est sélectionné à partir de”** - \"the inhibitor added is selected from\" - Clear and precise.\n",
      "*   **“alpha-1-antitrypsin humain”** - \"human α 1 -antitrypsin\" -  Direct translation.\n",
      "*   **“serum ou plasma contenant de l'alpha-1-antitrypsin humain”** - \"or plasma containing human α 1 -antitrypsin human\" -  A more precise and natural phrasing.\n",
      "*   **“une substance qui combine avec l'elastase d'une manière telle que…”** - \"a substance which combines with elastase in such a way that...\" -  This is a standard way to express the combined action.\n",
      "*   **“à inhiber l'activité de l'elastase”** - \"to inhibit elastase activity\" -  Direct and accurate.\n",
      "\n",
      "**Important Note:**  This translation is for a technical context.  If you need a translation for a general audience, you might need to simplify the language slightly.\n",
      "\n",
      "Do you have any specific context or area of focus for this translation?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable(value=-0.0, role=negative BLEU score, grads=set())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T16:57:17.860634Z",
     "start_time": "2026-01-09T16:57:17.828493Z"
    }
   },
   "cell_type": "code",
   "source": "sample",
   "id": "3fe2286f345e446d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'A method as claimed in Claim 1, wherein the inhibitor added is selected from human α 1 -antitrypsin, human serum or plasma containing human α 1 -antitrypsin, animal serum or plasma containing a substance which can combine with free elastase in such a way that human α 1 -antitrypsin combines therewith to inhibit elastase activity, and a synthetic material containing a substance which can combine with free elastase in such a way that human α 1 -antitrypsin combines therewith to inhibit elastase activity.',\n",
       " 'target': \"Un procédé selon la Revendication 1, dans lequel l'inhibiteur ajouté est sélectionné parmi l'α 1 -antitrypsine, du sérum ou du plasma humain contenant de l'α 1 -antitrypsine humaine, du sérum ou du plasma animal contenant une substance qui peut se combiner à l'élastase libre de telle sorte que l'α 1 -antitrypsine humaine s'y combine pour inhiber l'activité de l'élastase, et une matière synthétique contenant une substance qui peut se combiner à l'élastase libre de telle sorte que l'α 1 -antitrypsine s'y combine pour inhiber l'activité de l'élastase.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:08:00.097742Z",
     "start_time": "2026-01-09T17:07:59.061214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"openai/zongwei/gemma3-translator:1b\" , api_key=\"ollama\" , api_base=\"http://localhost:11434/v1/\")\n",
    "dspy.configure(lm=lm)"
   ],
   "id": "bb06ddb4f0264511",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:10:20.561814Z",
     "start_time": "2026-01-09T17:10:18.484407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "rag = dspy.ChainOfThought(\"question -> response\")\n",
    "\n",
    "question = \"Translate this sentence to French: What's the name of the castle that David Gregory inherited?\"\n",
    "rag(question=question)"
   ],
   "id": "a8fd8057c7330388",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The sentence is a straightforward question asking for the name of a castle. French doesn’t require a translation – it’s simply asking for the name.',\n",
       "    response='Le nom du château que David Gregory a hérité ?'\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:21:54.412886Z",
     "start_time": "2026-01-09T17:21:54.315473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dspy\n",
    "import sacrebleu\n",
    "\n",
    "# 1. Configure DSPy with your LLM\n",
    "# Make sure OPENAI_API_KEY is set in your environment variables\n",
    "lm = dspy.LM(\"openai/zongwei/gemma3-translator:1b\" , api_key=\"ollama\" , api_base=\"http://localhost:11434/v1/\")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "# 2. Define the Signature (Input/Output interface)\n",
    "class FrenchTranslation(dspy.Signature) :\n",
    "    \"\"\"Translate English sentences to French accurately and fluently.\"\"\"\n",
    "    english_sentence = dspy.InputField(desc=\"The sentence in English to translate.\")\n",
    "    french_translation = dspy.OutputField(desc=\"The translation in French.\")\n",
    "\n",
    "\n",
    "# 3. Define the Metric (BLEU Score)\n",
    "def bleu_metric(gold , pred , trace=None) :\n",
    "    \"\"\"\n",
    "    DSPy metric function.\n",
    "    - gold: The example from the dataset containing the ground truth.\n",
    "    - pred: The prediction object from the LLM containing the output.\n",
    "    \"\"\"\n",
    "    # Extract the hypothesis (prediction) and reference (gold)\n",
    "    hypothesis = [ pred.french_translation ]\n",
    "    references = [ [ gold.french_translation ] ]\n",
    "\n",
    "    # Calculate BLEU score using sacrebleu\n",
    "    bleu = sacrebleu.corpus_bleu(hypothesis , references)\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "# 4. Prepare Data (Trainset)\n",
    "# DSPy needs a small set of examples to \"bootstrap\" and optimize the prompt.\n",
    "trainset = [\n",
    "        dspy.Example(\n",
    "                english_sentence=\"The quick brown fox jumps over the lazy dog.\" ,\n",
    "                french_translation=\"Le vif renard brun saute par-dessus le chien paresseux.\"\n",
    "        ).with_inputs(\"english_sentence\") ,\n",
    "\n",
    "        dspy.Example(\n",
    "                english_sentence=\"Hello, how are you?\" ,\n",
    "                french_translation=\"Bonjour, comment allez-vous ?\"\n",
    "        ).with_inputs(\"english_sentence\") ,\n",
    "\n",
    "        dspy.Example(\n",
    "                english_sentence=\"Machine learning is fascinating.\" ,\n",
    "                french_translation=\"L'apprentissage automatique est fascinant.\"\n",
    "        ).with_inputs(\"english_sentence\") ,\n",
    "]\n",
    "\n",
    "# 5. Initialize the Student Program\n",
    "# We start with a basic Predict module.\n",
    "# DSPy will optimize this by filling in the \"few-shot\" examples in the prompt.\n",
    "translator = dspy.Predict(FrenchTranslation)\n",
    "\n",
    "# 6. Configure the Teleprompter (Optimizer)\n",
    "# BootstrapFewShot: Selects the best examples from the trainset to include in the prompt\n",
    "# to maximize the defined metric (BLEU score).\n",
    "teleprompter = dspy.BootstrapFewShot(\n",
    "        metric=bleu_metric ,\n",
    "        max_bootstrapped_demos=3 ,  # Number of examples to include in the final prompt\n",
    "        max_labeled_demos=1  # Number of fixed examples to always include\n",
    ")\n",
    "\n",
    "# 7. Compile (Optimize) the Program\n",
    "print(\"Compiling/Optimizing the translator based on BLEU score...\")\n",
    "optimized_translator = teleprompter.compile(student=translator , trainset=trainset)\n",
    "\n",
    "print(\"\\n--- Optimization Complete ---\")\n",
    "\n",
    "# 8. Test the Optimized Program\n",
    "test_sentence = \"The cat is sleeping on the mat.\"\n",
    "print(f\"\\nSource: {test_sentence}\")\n",
    "\n",
    "# Run the optimized program\n",
    "result = optimized_translator(english_sentence=test_sentence)\n",
    "\n",
    "# Print the Result\n",
    "print(f\"\\nTranslation: {result.french_translation}\")\n",
    "\n",
    "# --- Safe History Inspection (Debugging) ---\n",
    "# We wrap this in a check to avoid the TypeError if history is None/empty\n",
    "history = lm.inspect_history(n=1)\n",
    "if history :\n",
    "    print(\"\\n--- Last LLM Call (Prompt) ---\")\n",
    "    # We limit the print length to keep it readable\n",
    "    print(history[ -1 ][ 'messages' ][ 0 ][ 'content' ][ :500 ] + \"...\")\n",
    "else :\n",
    "    print(\"\\n[Note: LLM history tracking is empty or not available in this configuration]\")\n",
    "\n",
    "# Optional: Calculate BLEU for this specific test if you have a reference\n",
    "reference = \"Le chat dort sur le tapis.\"\n",
    "bleu_test = sacrebleu.corpus_bleu([ result.french_translation ] , [ [ reference ] ])\n",
    "print(f\"\\nTest BLEU Score (vs reference): {bleu_test.score:.2f}\")"
   ],
   "id": "6603beab319d2cb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling/Optimizing the translator based on BLEU score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 67.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "--- Optimization Complete ---\n",
      "\n",
      "Source: The cat is sleeping on the mat.\n",
      "\n",
      "Translation: Le chat dort sur le tapis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[34m[2026-01-09T18:21:54.387267]\u001B[0m\n",
      "\n",
      "\u001B[31mSystem message:\u001B[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `english_sentence` (str): The sentence in English to translate.\n",
      "Your output fields are:\n",
      "1. `french_translation` (str): The translation in French.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "{english_sentence}\n",
      "\n",
      "[[ ## french_translation ## ]]\n",
      "{french_translation}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Translate English sentences to French accurately and fluently.\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "\n",
      "\u001B[31mAssistant message:\u001B[0m\n",
      "\n",
      "[[ ## french_translation ## ]]\n",
      "Le rapide renard brun saute par-dessus le chien paresseux.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "Hello, how are you?\n",
      "\n",
      "\n",
      "\u001B[31mAssistant message:\u001B[0m\n",
      "\n",
      "[[ ## french_translation ## ]]\n",
      "Bonjour, comment allez-vous ?\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "The cat is sleeping on the mat.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## french_translation ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001B[31mResponse:\u001B[0m\n",
      "\n",
      "\u001B[32m[[ ## french_translation ## ]]\n",
      "Le chat dort sur le tapis.\n",
      "\n",
      "[[ ## completed ## ]]\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Note: LLM history tracking is empty or not available in this configuration]\n",
      "\n",
      "Test BLEU Score (vs reference): 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:27:34.220685Z",
     "start_time": "2026-01-09T17:27:07.103642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa = dspy.Predict('question: str -> response: str')\n",
    "response = qa(question=\"what are high memory and low memory on linux?\")\n",
    "\n",
    "print(response.response)"
   ],
   "id": "64eaa6e18f8a4c78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High and low memory usage on Linux are complex and depend heavily on the specific workload and configuration. However, here’s a breakdown of general trends and factors:\n",
      "\n",
      "**High Memory Usage (Generally indicates potential for performance issues):**\n",
      "\n",
      "*   **Memory Leaks:** A common problem is memory leaks – where memory is allocated but never released.\n",
      "*   **Large Applications/Processes:** Applications or processes that consume a lot of memory, especially during long-running tasks, can cause high memory usage.\n",
      "*   **Memory-Intensive Tasks:** Tasks like video encoding, large database queries, or scientific simulations often have a significant memory footprint.\n",
      "*   **Unoptimized Code:** Poorly written code can lead to excessive memory allocation.\n",
      "*   **Insufficient RAM:** If the overall system has insufficient RAM to handle the load, higher memory usage becomes unavoidable.\n",
      "*   **Data-Driven Systems:**  If a system relies heavily on reading data from disk (e.g., databases), memory pressure increases.\n",
      "\n",
      "**Low Memory Usage (Generally indicates system stability and responsiveness):**\n",
      "\n",
      "*   **Lightweight Applications:** Applications designed for minimal resource usage often consume less memory.\n",
      "*   **Efficient Algorithms:** Using efficient algorithms and data structures can reduce memory consumption.\n",
      "*   **Optimized Code:** Well-optimized code minimizes memory allocation.\n",
      "*   **Memory Mapping:** Using memory mapping techniques can reduce the need to repeatedly allocate and deallocate memory.\n",
      "*   **Caching:**  Caching frequently accessed data can significantly reduce memory usage by avoiding redundant computations.\n",
      "*   **System Load:** A healthy system with minimal tasks often consumes less memory.\n",
      "\n",
      "**Factors Affecting Memory Usage:**\n",
      "\n",
      "*   **Number of Processes:** More running processes automatically consume more memory.\n",
      "*   **File Handles:**  Opening and closing files creates file handles, which consume memory.\n",
      "*   **Databases:** Database operations are a major memory consumer, especially when many queries are being performed.\n",
      "*   **System Services:** Services like networking, printing, and system monitoring consume memory.\n",
      "*   **User Profile:** The user’s desktop environment and applications also consume memory.\n",
      "\n",
      "**Tools for Monitoring:**\n",
      "\n",
      "*   **`top`:** Shows real-time process and memory usage.\n",
      "*   **`htop`:** An enhanced version of `top` that provides more detailed information.\n",
      "*   **`free`:** Displays available, used, and cached memory.\n",
      "*   **`vmstat`:** Provides system-level statistics, including memory usage.\n",
      "*   **`ps`:** Shows process information, including memory usage.\n",
      "\n",
      "**Linux Specific Considerations:**\n",
      "\n",
      "*   **Swap Space:**  The amount of swap space significantly impacts memory usage. More swap can delay usage of RAM,\n",
      "*   **Kernel Memory Management:** Linux has sophisticated memory management, but it can still become a bottleneck if not configured properly.\n",
      "*   **`VGTRAN`:** This is the mechanism Linux uses to manage memory between the kernel and the system, and it has a significant impact on overall memory usage.\n",
      "\n",
      "**It's important to note:**  Memory usage is often not a straightforward number. It’s often better to consider the *pattern* of usage – for example, spikes in memory usage might indicate a problem.\n",
      "\n",
      "In short, it’s a balance between using *less* memory and ensuring there’s enough available to handle all your workloads efficiently.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:28:03.962849Z",
     "start_time": "2026-01-09T17:28:03.895698Z"
    }
   },
   "cell_type": "code",
   "source": "dspy.inspect_history(n=1)",
   "id": "e735f3168b493bab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[34m[2026-01-09T18:27:34.156401]\u001B[0m\n",
      "\n",
      "\u001B[31mSystem message:\u001B[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `response` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"response\": \"{response}\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `response`.\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "what are high memory and low memory on linux?\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `response`.\n",
      "\n",
      "\n",
      "\u001B[31mResponse:\u001B[0m\n",
      "\n",
      "\u001B[32m{\n",
      "  \"response\": \"High and low memory usage on Linux are complex and depend heavily on the specific workload and configuration. However, here’s a breakdown of general trends and factors:\\n\\n**High Memory Usage (Generally indicates potential for performance issues):**\\n\\n*   **Memory Leaks:** A common problem is memory leaks – where memory is allocated but never released.\\n*   **Large Applications/Processes:** Applications or processes that consume a lot of memory, especially during long-running tasks, can cause high memory usage.\\n*   **Memory-Intensive Tasks:** Tasks like video encoding, large database queries, or scientific simulations often have a significant memory footprint.\\n*   **Unoptimized Code:** Poorly written code can lead to excessive memory allocation.\\n*   **Insufficient RAM:** If the overall system has insufficient RAM to handle the load, higher memory usage becomes unavoidable.\\n*   **Data-Driven Systems:**  If a system relies heavily on reading data from disk (e.g., databases), memory pressure increases.\\n\\n**Low Memory Usage (Generally indicates system stability and responsiveness):**\\n\\n*   **Lightweight Applications:** Applications designed for minimal resource usage often consume less memory.\\n*   **Efficient Algorithms:** Using efficient algorithms and data structures can reduce memory consumption.\\n*   **Optimized Code:** Well-optimized code minimizes memory allocation.\\n*   **Memory Mapping:** Using memory mapping techniques can reduce the need to repeatedly allocate and deallocate memory.\\n*   **Caching:**  Caching frequently accessed data can significantly reduce memory usage by avoiding redundant computations.\\n*   **System Load:** A healthy system with minimal tasks often consumes less memory.\\n\\n**Factors Affecting Memory Usage:**\\n\\n*   **Number of Processes:** More running processes automatically consume more memory.\\n*   **File Handles:**  Opening and closing files creates file handles, which consume memory.\\n*   **Databases:** Database operations are a major memory consumer, especially when many queries are being performed.\\n*   **System Services:** Services like networking, printing, and system monitoring consume memory.\\n*   **User Profile:** The user’s desktop environment and applications also consume memory.\\n\\n**Tools for Monitoring:**\\n\\n*   **`top`:** Shows real-time process and memory usage.\\n*   **`htop`:** An enhanced version of `top` that provides more detailed information.\\n*   **`free`:** Displays available, used, and cached memory.\\n*   **`vmstat`:** Provides system-level statistics, including memory usage.\\n*   **`ps`:** Shows process information, including memory usage.\\n\\n**Linux Specific Considerations:**\\n\\n*   **Swap Space:**  The amount of swap space significantly impacts memory usage. More swap can delay usage of RAM,\\n*   **Kernel Memory Management:** Linux has sophisticated memory management, but it can still become a bottleneck if not configured properly.\\n*   **`VGTRAN`:** This is the mechanism Linux uses to manage memory between the kernel and the system, and it has a significant impact on overall memory usage.\\n\\n**It's important to note:**  Memory usage is often not a straightforward number. It’s often better to consider the *pattern* of usage – for example, spikes in memory usage might indicate a problem.\\n\\nIn short, it’s a balance between using *less* memory and ensuring there’s enough available to handle all your workloads efficiently.\"\n",
      "\n",
      "}\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "88bf0518a6b7a1dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
