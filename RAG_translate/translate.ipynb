{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T08:19:49.176653Z",
     "start_time": "2026-01-10T08:19:46.446508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from vector_db import VectorDB"
   ],
   "id": "3fe2286f345e446d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.\n",
      "  `use_auth_token` will definitely not be supported.\n",
      "2026-01-10 09:19:47.195 python[2945:173223] 2026-01-10 09:19:47.194341 [W:onnxruntime:, coreml_execution_provider.cc:113 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 20 number of nodes in the graph: 205 number of nodes supported by CoreML: 133\n",
      "2026-01-10 09:19:47.684 python[2945:173223] 2026-01-10 09:19:47.683995 [W:onnxruntime:, coreml_execution_provider.cc:113 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 112 number of nodes in the graph: 1056 number of nodes supported by CoreML: 739\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T08:19:56.297393Z",
     "start_time": "2026-01-10T08:19:53.319888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = load_dataset(\"aimped/medical-translation-test-set\")[ \"en_fr\" ]\n",
    "\n",
    "# Shuffle the dataset\n",
    "ds = ds.shuffle(seed=42)\n",
    "# split into train_set, val_set, test_set\n",
    "train_size = int(0.8 * len(ds))\n",
    "val_size = int(0.1 * len(ds))\n",
    "test_size = len(ds) - train_size - val_size\n",
    "\n",
    "train_set = ds.select(range(train_size))\n",
    "val_set = ds.select(range(train_size , train_size + val_size))\n",
    "test_set = ds.select(range(train_size + val_size , len(ds)))\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Validation set size: {len(val_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")"
   ],
   "id": "459ccd1376dfab30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 839\n",
      "Validation set size: 104\n",
      "Test set size: 106\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T08:20:34.490476Z",
     "start_time": "2026-01-10T08:19:57.234144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_db = VectorDB( )\n",
    "for item in train_set :\n",
    "    text = f\"English: {item[ 'source' ]} French: {item[ 'target' ]}\"\n",
    "    vector_db.add_entry(text , item[ \"target\" ])\n",
    "print(\"Finished adding entries to the vector database.\")"
   ],
   "id": "d18e177a695b24c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding entries to the vector database.\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T09:51:30.028610Z",
     "start_time": "2026-01-10T09:51:29.992093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"openai/zongwei/gemma3-translator:1b\" , api_key=\"ollama\" , api_base=\"http://localhost:11434/v1/\")\n",
    "dspy.configure(lm=lm)"
   ],
   "id": "bb06ddb4f0264511",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T09:51:31.050127Z",
     "start_time": "2026-01-10T09:51:30.902852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "rag = dspy.ChainOfThought(\"question -> response\")\n",
    "\n",
    "question = \"Translate this sentence to French: \" + test_set[ \"source\" ][ 0 ]\n",
    "rag(question=question)"
   ],
   "id": "a8fd8057c7330388",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The data suggests a significantly different peak levels of IL-6, PCT, and CRP between the known pathogen group and the control group. The coagulase-negative group exhibited lower levels of these biomarkers compared to the negative culture group, while the control group had the lowest levels.',\n",
       "    response='Interleukin (IL-6), procalcitonin (PCT), and C-reactive protein (CRP) levels were highest among the known pathogen group (IL-6 271.8 U/L, PCT 4.6 U/L and CRP 164 mg/L), and were similar between the coagulase-negative Staphylococcus and negative culture groups (IL-6 67.0 U/L versus 61.4 U/L [P=1.00]; PCT 1.0 U/L versus 0.9 U/L [P=0.80]; and CRP 110 mg/L versus 103 mg/L [P=0.75]), and were lowest in the control group (IL-6 31.0 U/L, PCT 0.2 U/L and CRP 41.0 mg/L).'\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T08:22:53.322891Z",
     "start_time": "2026-01-10T08:22:53.232518Z"
    }
   },
   "cell_type": "code",
   "source": "test_set[ \"source\" ][ 0 ]",
   "id": "ad1c2dd8e394c6d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interleukin (IL)-6, procalcitonin (PCT) and C-reactive protein (CRP) levels were highest among the known pathogen group (IL-6 271.8 U/L, PCT 4.6 U/L and CRP 164 mg/L), were similar between the coagulase-negative Staphylococcus and negative culture groups (IL-6 67.0 U/L versus 61.4 U/L [P=1.00]; PCT 1.0 U/L versus 0.9 U/L [P=0.80]; and CRP 110 mg/L versus 103 mg/L [P=0.75]), and were lowest in the control group (IL-6 31.0 U/L, PCT 0.2 U/L and CRP 41.0 mg/L).'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T09:51:34.941451Z",
     "start_time": "2026-01-10T09:51:34.900261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RAG(dspy.Module) :\n",
    "    def __init__(self) :\n",
    "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
    "\n",
    "    def forward(self , question) :\n",
    "        context = vector_db.get_entry(question , top_k=5)\n",
    "        context = \" \".join(context)\n",
    "        question = \"Translate this sentence to French: \" + question\n",
    "        return self.respond(context=context , question=question)"
   ],
   "id": "1b65657d0bba0aa9",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T09:51:35.769515Z",
     "start_time": "2026-01-10T09:51:35.600238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag = RAG( )\n",
    "question = test_set[ \"source\" ][ 0 ]\n",
    "rag(question=question)"
   ],
   "id": "d3ce451f84a6105",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The sentence describes a comparison of serum levels of IL-6, PCT, and CRP across different groups. The levels of these proteins were significantly higher in the “known pathogen group” than in other groups, particularly the coagulase-negative and negative cultures. The levels were relatively similar between the two groups of cultures.  The control group had the lowest levels of all these proteins.',\n",
       "    response='Le niveau des cytokines IL-6, de la procalcitonine (PCT) et du CRP était le plus élevé parmi les groupes connus de pathogènes (IL-6 271,8 U/L, PCT 4,6 U/L, et CRP 164 mg/L), tandis que les niveaux étaient similaires entre les groupes de culture coagulase-négatifs et négatifs (IL-6 67,0 U/L vs 61,4 U/L [P=1,00]; PCT 1,0 U/L vs 0,9 U/L [P=0,80]; et CRP 110 mg/L vs 103 mg/L [P=0,75]).  Les niveaux étaient les plus bas dans le groupe de contrôle (IL-6 31,0 U/L, PCT 0,2 U/L et CRP 41,0 mg/L).'\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T09:51:39.468257Z",
     "start_time": "2026-01-10T09:51:39.426550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dspy.evaluate import SemanticF1\n",
    "\n",
    "# Instantiate the metric.\n",
    "metric = SemanticF1(decompositional=True)\n",
    "\n",
    "# Define an evaluator that we can re-use.\n"
   ],
   "id": "6ae4dadbb3e7e97",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T09:57:34.113571Z",
     "start_time": "2026-01-10T09:54:38.670679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formatted_test_set = [\n",
    "        dspy.Example(question=item[ 'source' ] , response=item[ 'target' ]).with_inputs('question')\n",
    "        for item in test_set\n",
    "]\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=formatted_test_set , metric=metric , num_threads=1 ,\n",
    "                         display_progress=True , display_table=2)\n",
    "# Now run the evaluation with the formatted set\n",
    "# We reduce num_threads to 1 to see clearer error messages if it fails again\n",
    "# and use the RAG instance directly.\n",
    "rag_module = RAG( )\n",
    "evaluate(rag_module , devset=formatted_test_set , num_threads=1 , metric=metric ,\n",
    "         display_progress=True , display_table=5)"
   ],
   "id": "26f2d7b0cb29adf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.46 / 20 (52.3%):  18%|█▊        | 19/106 [00:00<00:03, 27.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 10:54:39 ERROR dspy.utils.parallelizer: Error for Example({'question': 'A pharmaceutical or veterinary composition as claimed in claim 30 which is adapted for oral administration', 'response': 'Composition pharmaceutique ou vétérinaire selon la revendication 30, qui est adaptée à une administration orale'}) (input_keys={'question'}): Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\n",
      "  \"reasoning\": \"The system response explicitly states that the composition is adapted for oral administration, directly addressing the core of the question and comparison with the ground truth.\",\n",
      "  \"ground_truth_key_ideas\": [\"administration orale\", \"pharmaceutical composition\", \"adapted for oral administration\", \"formulation designed for oral\"]\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      " \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, ground_truth_key_ideas, system_response_key_ideas, discussion, recall, precision] \n",
      "\n",
      "Actual output fields parsed from the LM response: [reasoning, ground_truth_key_ideas] \n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 210, in parse\n",
      "    fields[k] = parse_value(v, signature.output_fields[k].annotation)\n",
      "                ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/utils.py\", line 179, in parse_value\n",
      "    return TypeAdapter(annotation).validate_python(candidate)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/pydantic/type_adapter.py\", line 441, in validate_python\n",
      "    return self.validator.validate_python(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        object,\n",
      "        ^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        by_name=by_name,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "pydantic_core._pydantic_core.ValidationError: 1 validation error for float\n",
      "  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='0.8\\n```', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/float_parsing\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 52, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 203, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs, lm, lm_kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 137, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 212, in parse\n",
      "    raise AdapterParseError(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "dspy.utils.exceptions.AdapterParseError: Failed to parse field precision with value 0.8\n",
      "``` from the LM response. Error message: 1 validation error for float\n",
      "  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='0.8\\n```', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/float_parsing\n",
      "\n",
      "Adapter ChatAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: ```python\n",
      "[[ ## reasoning ## ]]\n",
      "The system response accurately describes the composition's adaptation for oral administration, mirroring the ground truth. It’s a straightforward statement of purpose.\n",
      "\n",
      "[[ ## ground_truth_key_ideas ## ]]\n",
      "- Pharmaceutical or veterinary composition adapted for oral administration\n",
      "- Formulation tailored for oral delivery\n",
      "\n",
      "[[ ## system_response_key_ideas ## ]]\n",
      "- The composition will have a formulation suitable for oral administration.\n",
      "\n",
      "[[ ## discussion ## ]]\n",
      "The system response directly confirms the core claim of the ground truth; it’s a clear and concise statement of adaptation.  There’s no significant overlap or variance between the two.\n",
      "\n",
      "[[ ## recall ## ]]\n",
      "0.8\n",
      "\n",
      "[[ ## precision ## ]]\n",
      "0.8\n",
      "``` \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, ground_truth_key_ideas, system_response_key_ideas, discussion, recall, precision] \n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/parallelizer.py\", line 57, in safe_func\n",
      "    return user_function(item)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/evaluate/evaluate.py\", line 172, in process_item\n",
      "    score = metric(example, prediction)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 82, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/evaluate/auto_evaluation.py\", line 50, in forward\n",
      "    scores = self.module(question=example.question, ground_truth=example.response, system_response=pred.response)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 82, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/predict/chain_of_thought.py\", line 37, in forward\n",
      "    return self.predict(**kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n",
      "    return super().__call__(**kwargs)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 82, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n",
      "    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 65, in __call__\n",
      "    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 73, in __call__\n",
      "    result = self._json_adapter_call_common(lm, lm_kwargs, signature, demos, inputs, super().__call__)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 63, in _json_adapter_call_common\n",
      "    return call_fn(lm, lm_kwargs, signature, demos, inputs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 64, in __call__\n",
      "    raise e\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 52, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 203, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs, lm, lm_kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 137, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "  File \"/Users/jonathansuru/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 176, in parse\n",
      "    raise AdapterParseError(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "dspy.utils.exceptions.AdapterParseError: Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\n",
      "  \"reasoning\": \"The system response explicitly states that the composition is adapted for oral administration, directly addressing the core of the question and comparison with the ground truth.\",\n",
      "  \"ground_truth_key_ideas\": [\"administration orale\", \"pharmaceutical composition\", \"adapted for oral administration\", \"formulation designed for oral\"]\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      " \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, ground_truth_key_ideas, system_response_key_ideas, discussion, recall, precision] \n",
      "\n",
      "Actual output fields parsed from the LM response: [reasoning, ground_truth_key_ideas] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.54 / 71 (55.7%):  68%|██████▊   | 72/106 [02:52<05:56, 10.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 10:57:33 WARNING dspy.utils.parallelizer: SIGINT received. Cancelling.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[88]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Now run the evaluation with the formatted set\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# We reduce num_threads to 1 to see clearer error messages if it fails again\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m# and use the RAG instance directly.\u001B[39;00m\n\u001B[32m     11\u001B[39m rag_module = RAG( )\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrag_module\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mformatted_test_set\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_threads\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m         \u001B[49m\u001B[43mdisplay_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisplay_table\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/callback.py:326\u001B[39m, in \u001B[36mwith_callbacks.<locals>.sync_wrapper\u001B[39m\u001B[34m(instance, *args, **kwargs)\u001B[39m\n\u001B[32m    324\u001B[39m callbacks = _get_active_callbacks(instance)\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callbacks:\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    328\u001B[39m call_id = uuid.uuid4().hex\n\u001B[32m    330\u001B[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/evaluate/evaluate.py:175\u001B[39m, in \u001B[36mEvaluate.__call__\u001B[39m\u001B[34m(self, program, metric, devset, num_threads, display_progress, display_table, callback_metadata, save_as_csv, save_as_json)\u001B[39m\n\u001B[32m    172\u001B[39m     score = metric(example, prediction)\n\u001B[32m    173\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m prediction, score\n\u001B[32m--> \u001B[39m\u001B[32m175\u001B[39m results = \u001B[43mexecutor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_item\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(devset) == \u001B[38;5;28mlen\u001B[39m(results)\n\u001B[32m    178\u001B[39m results = [((dspy.Prediction(), \u001B[38;5;28mself\u001B[39m.failure_score) \u001B[38;5;28;01mif\u001B[39;00m r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m r) \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m results]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/parallelizer.py:50\u001B[39m, in \u001B[36mParallelExecutor.execute\u001B[39m\u001B[34m(self, function, data)\u001B[39m\n\u001B[32m     48\u001B[39m tqdm.tqdm._instances.clear()\n\u001B[32m     49\u001B[39m wrapped = \u001B[38;5;28mself\u001B[39m._wrap_function(function)\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_execute_parallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrapped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/parallelizer.py:151\u001B[39m, in \u001B[36mParallelExecutor._execute_parallel\u001B[39m\u001B[34m(self, function, data)\u001B[39m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m all_done():\n\u001B[32m    150\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m151\u001B[39m done, not_done = \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_when\u001B[49m\u001B[43m=\u001B[49m\u001B[43mFIRST_COMPLETED\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m done:\n\u001B[32m    153\u001B[39m     futures_set.remove(f)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.11-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:305\u001B[39m, in \u001B[36mwait\u001B[39m\u001B[34m(fs, timeout, return_when)\u001B[39m\n\u001B[32m    301\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001B[32m    303\u001B[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001B[32m--> \u001B[39m\u001B[32m305\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fs:\n\u001B[32m    307\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m f._condition:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.11-macos-aarch64-none/lib/python3.13/threading.py:660\u001B[39m, in \u001B[36mEvent.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    658\u001B[39m signaled = \u001B[38;5;28mself\u001B[39m._flag\n\u001B[32m    659\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[32m--> \u001B[39m\u001B[32m660\u001B[39m     signaled = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_cond\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    661\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.11-macos-aarch64-none/lib/python3.13/threading.py:363\u001B[39m, in \u001B[36mCondition.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    361\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    362\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout > \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m363\u001B[39m         gotit = \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    364\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    365\u001B[39m         gotit = waiter.acquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/OpenLabs/.venv/lib/python3.13/site-packages/dspy/utils/parallelizer.py:111\u001B[39m, in \u001B[36mParallelExecutor._execute_parallel.<locals>.interrupt_manager.<locals>.handler\u001B[39m\u001B[34m(sig, frame)\u001B[39m\n\u001B[32m    109\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_jobs.set()\n\u001B[32m    110\u001B[39m logger.warning(\u001B[33m\"\u001B[39m\u001B[33mSIGINT received. Cancelling.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m \u001B[43morig_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[43msig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:21:54.412886Z",
     "start_time": "2026-01-09T17:21:54.315473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dspy\n",
    "import sacrebleu\n",
    "\n",
    "# 1. Configure DSPy with your LLM\n",
    "# Make sure OPENAI_API_KEY is set in your environment variables\n",
    "lm = dspy.LM(\"openai/zongwei/gemma3-translator:1b\" , api_key=\"ollama\" , api_base=\"http://localhost:11434/v1/\")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "# 2. Define the Signature (Input/Output interface)\n",
    "class FrenchTranslation(dspy.Signature) :\n",
    "    \"\"\"Translate English sentences to French accurately and fluently.\"\"\"\n",
    "    english_sentence = dspy.InputField(desc=\"The sentence in English to translate.\")\n",
    "    french_translation = dspy.OutputField(desc=\"The translation in French.\")\n",
    "\n",
    "\n",
    "# 3. Define the Metric (BLEU Score)\n",
    "def bleu_metric(gold , pred , trace=None) :\n",
    "    \"\"\"\n",
    "    DSPy metric function.\n",
    "    - gold: The example from the dataset containing the ground truth.\n",
    "    - pred: The prediction object from the LLM containing the output.\n",
    "    \"\"\"\n",
    "    # Extract the hypothesis (prediction) and reference (gold)\n",
    "    hypothesis = [ pred.french_translation ]\n",
    "    references = [ [ gold.french_translation ] ]\n",
    "\n",
    "    # Calculate BLEU score using sacrebleu\n",
    "    bleu = sacrebleu.corpus_bleu(hypothesis , references)\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "# 4. Prepare Data (Trainset)\n",
    "# DSPy needs a small set of examples to \"bootstrap\" and optimize the prompt.\n",
    "trainset = [\n",
    "        dspy.Example(\n",
    "                english_sentence=\"The quick brown fox jumps over the lazy dog.\" ,\n",
    "                french_translation=\"Le vif renard brun saute par-dessus le chien paresseux.\"\n",
    "        ).with_inputs(\"english_sentence\") ,\n",
    "\n",
    "        dspy.Example(\n",
    "                english_sentence=\"Hello, how are you?\" ,\n",
    "                french_translation=\"Bonjour, comment allez-vous ?\"\n",
    "        ).with_inputs(\"english_sentence\") ,\n",
    "\n",
    "        dspy.Example(\n",
    "                english_sentence=\"Machine learning is fascinating.\" ,\n",
    "                french_translation=\"L'apprentissage automatique est fascinant.\"\n",
    "        ).with_inputs(\"english_sentence\") ,\n",
    "]\n",
    "\n",
    "# 5. Initialize the Student Program\n",
    "# We start with a basic Predict module.\n",
    "# DSPy will optimize this by filling in the \"few-shot\" examples in the prompt.\n",
    "translator = dspy.Predict(FrenchTranslation)\n",
    "\n",
    "# 6. Configure the Teleprompter (Optimizer)\n",
    "# BootstrapFewShot: Selects the best examples from the trainset to include in the prompt\n",
    "# to maximize the defined metric (BLEU score).\n",
    "teleprompter = dspy.BootstrapFewShot(\n",
    "        metric=bleu_metric ,\n",
    "        max_bootstrapped_demos=3 ,  # Number of examples to include in the final prompt\n",
    "        max_labeled_demos=1  # Number of fixed examples to always include\n",
    ")\n",
    "\n",
    "# 7. Compile (Optimize) the Program\n",
    "print(\"Compiling/Optimizing the translator based on BLEU score...\")\n",
    "optimized_translator = teleprompter.compile(student=translator , trainset=trainset)\n",
    "\n",
    "print(\"\\n--- Optimization Complete ---\")\n",
    "\n",
    "# 8. Test the Optimized Program\n",
    "test_sentence = \"The cat is sleeping on the mat.\"\n",
    "print(f\"\\nSource: {test_sentence}\")\n",
    "\n",
    "# Run the optimized program\n",
    "result = optimized_translator(english_sentence=test_sentence)\n",
    "\n",
    "# Print the Result\n",
    "print(f\"\\nTranslation: {result.french_translation}\")\n",
    "\n",
    "# --- Safe History Inspection (Debugging) ---\n",
    "# We wrap this in a check to avoid the TypeError if history is None/empty\n",
    "history = lm.inspect_history(n=1)\n",
    "if history :\n",
    "    print(\"\\n--- Last LLM Call (Prompt) ---\")\n",
    "    # We limit the print length to keep it readable\n",
    "    print(history[ -1 ][ 'messages' ][ 0 ][ 'content' ][ :500 ] + \"...\")\n",
    "else :\n",
    "    print(\"\\n[Note: LLM history tracking is empty or not available in this configuration]\")\n",
    "\n",
    "# Optional: Calculate BLEU for this specific test if you have a reference\n",
    "reference = \"Le chat dort sur le tapis.\"\n",
    "bleu_test = sacrebleu.corpus_bleu([ result.french_translation ] , [ [ reference ] ])\n",
    "print(f\"\\nTest BLEU Score (vs reference): {bleu_test.score:.2f}\")"
   ],
   "id": "6603beab319d2cb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling/Optimizing the translator based on BLEU score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 67.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "--- Optimization Complete ---\n",
      "\n",
      "Source: The cat is sleeping on the mat.\n",
      "\n",
      "Translation: Le chat dort sur le tapis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[34m[2026-01-09T18:21:54.387267]\u001B[0m\n",
      "\n",
      "\u001B[31mSystem message:\u001B[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `english_sentence` (str): The sentence in English to translate.\n",
      "Your output fields are:\n",
      "1. `french_translation` (str): The translation in French.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "{english_sentence}\n",
      "\n",
      "[[ ## french_translation ## ]]\n",
      "{french_translation}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Translate English sentences to French accurately and fluently.\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "\n",
      "\u001B[31mAssistant message:\u001B[0m\n",
      "\n",
      "[[ ## french_translation ## ]]\n",
      "Le rapide renard brun saute par-dessus le chien paresseux.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "Hello, how are you?\n",
      "\n",
      "\n",
      "\u001B[31mAssistant message:\u001B[0m\n",
      "\n",
      "[[ ## french_translation ## ]]\n",
      "Bonjour, comment allez-vous ?\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## english_sentence ## ]]\n",
      "The cat is sleeping on the mat.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## french_translation ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001B[31mResponse:\u001B[0m\n",
      "\n",
      "\u001B[32m[[ ## french_translation ## ]]\n",
      "Le chat dort sur le tapis.\n",
      "\n",
      "[[ ## completed ## ]]\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Note: LLM history tracking is empty or not available in this configuration]\n",
      "\n",
      "Test BLEU Score (vs reference): 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:27:34.220685Z",
     "start_time": "2026-01-09T17:27:07.103642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa = dspy.Predict('question: str -> response: str')\n",
    "response = qa(question=\"what are high memory and low memory on linux?\")\n",
    "\n",
    "print(response.response)"
   ],
   "id": "64eaa6e18f8a4c78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High and low memory usage on Linux are complex and depend heavily on the specific workload and configuration. However, here’s a breakdown of general trends and factors:\n",
      "\n",
      "**High Memory Usage (Generally indicates potential for performance issues):**\n",
      "\n",
      "*   **Memory Leaks:** A common problem is memory leaks – where memory is allocated but never released.\n",
      "*   **Large Applications/Processes:** Applications or processes that consume a lot of memory, especially during long-running tasks, can cause high memory usage.\n",
      "*   **Memory-Intensive Tasks:** Tasks like video encoding, large database queries, or scientific simulations often have a significant memory footprint.\n",
      "*   **Unoptimized Code:** Poorly written code can lead to excessive memory allocation.\n",
      "*   **Insufficient RAM:** If the overall system has insufficient RAM to handle the load, higher memory usage becomes unavoidable.\n",
      "*   **Data-Driven Systems:**  If a system relies heavily on reading data from disk (e.g., databases), memory pressure increases.\n",
      "\n",
      "**Low Memory Usage (Generally indicates system stability and responsiveness):**\n",
      "\n",
      "*   **Lightweight Applications:** Applications designed for minimal resource usage often consume less memory.\n",
      "*   **Efficient Algorithms:** Using efficient algorithms and data structures can reduce memory consumption.\n",
      "*   **Optimized Code:** Well-optimized code minimizes memory allocation.\n",
      "*   **Memory Mapping:** Using memory mapping techniques can reduce the need to repeatedly allocate and deallocate memory.\n",
      "*   **Caching:**  Caching frequently accessed data can significantly reduce memory usage by avoiding redundant computations.\n",
      "*   **System Load:** A healthy system with minimal tasks often consumes less memory.\n",
      "\n",
      "**Factors Affecting Memory Usage:**\n",
      "\n",
      "*   **Number of Processes:** More running processes automatically consume more memory.\n",
      "*   **File Handles:**  Opening and closing files creates file handles, which consume memory.\n",
      "*   **Databases:** Database operations are a major memory consumer, especially when many queries are being performed.\n",
      "*   **System Services:** Services like networking, printing, and system monitoring consume memory.\n",
      "*   **User Profile:** The user’s desktop environment and applications also consume memory.\n",
      "\n",
      "**Tools for Monitoring:**\n",
      "\n",
      "*   **`top`:** Shows real-time process and memory usage.\n",
      "*   **`htop`:** An enhanced version of `top` that provides more detailed information.\n",
      "*   **`free`:** Displays available, used, and cached memory.\n",
      "*   **`vmstat`:** Provides system-level statistics, including memory usage.\n",
      "*   **`ps`:** Shows process information, including memory usage.\n",
      "\n",
      "**Linux Specific Considerations:**\n",
      "\n",
      "*   **Swap Space:**  The amount of swap space significantly impacts memory usage. More swap can delay usage of RAM,\n",
      "*   **Kernel Memory Management:** Linux has sophisticated memory management, but it can still become a bottleneck if not configured properly.\n",
      "*   **`VGTRAN`:** This is the mechanism Linux uses to manage memory between the kernel and the system, and it has a significant impact on overall memory usage.\n",
      "\n",
      "**It's important to note:**  Memory usage is often not a straightforward number. It’s often better to consider the *pattern* of usage – for example, spikes in memory usage might indicate a problem.\n",
      "\n",
      "In short, it’s a balance between using *less* memory and ensuring there’s enough available to handle all your workloads efficiently.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T17:28:03.962849Z",
     "start_time": "2026-01-09T17:28:03.895698Z"
    }
   },
   "cell_type": "code",
   "source": "dspy.inspect_history(n=1)",
   "id": "e735f3168b493bab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[34m[2026-01-09T18:27:34.156401]\u001B[0m\n",
      "\n",
      "\u001B[31mSystem message:\u001B[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `response` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"response\": \"{response}\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `response`.\n",
      "\n",
      "\n",
      "\u001B[31mUser message:\u001B[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "what are high memory and low memory on linux?\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `response`.\n",
      "\n",
      "\n",
      "\u001B[31mResponse:\u001B[0m\n",
      "\n",
      "\u001B[32m{\n",
      "  \"response\": \"High and low memory usage on Linux are complex and depend heavily on the specific workload and configuration. However, here’s a breakdown of general trends and factors:\\n\\n**High Memory Usage (Generally indicates potential for performance issues):**\\n\\n*   **Memory Leaks:** A common problem is memory leaks – where memory is allocated but never released.\\n*   **Large Applications/Processes:** Applications or processes that consume a lot of memory, especially during long-running tasks, can cause high memory usage.\\n*   **Memory-Intensive Tasks:** Tasks like video encoding, large database queries, or scientific simulations often have a significant memory footprint.\\n*   **Unoptimized Code:** Poorly written code can lead to excessive memory allocation.\\n*   **Insufficient RAM:** If the overall system has insufficient RAM to handle the load, higher memory usage becomes unavoidable.\\n*   **Data-Driven Systems:**  If a system relies heavily on reading data from disk (e.g., databases), memory pressure increases.\\n\\n**Low Memory Usage (Generally indicates system stability and responsiveness):**\\n\\n*   **Lightweight Applications:** Applications designed for minimal resource usage often consume less memory.\\n*   **Efficient Algorithms:** Using efficient algorithms and data structures can reduce memory consumption.\\n*   **Optimized Code:** Well-optimized code minimizes memory allocation.\\n*   **Memory Mapping:** Using memory mapping techniques can reduce the need to repeatedly allocate and deallocate memory.\\n*   **Caching:**  Caching frequently accessed data can significantly reduce memory usage by avoiding redundant computations.\\n*   **System Load:** A healthy system with minimal tasks often consumes less memory.\\n\\n**Factors Affecting Memory Usage:**\\n\\n*   **Number of Processes:** More running processes automatically consume more memory.\\n*   **File Handles:**  Opening and closing files creates file handles, which consume memory.\\n*   **Databases:** Database operations are a major memory consumer, especially when many queries are being performed.\\n*   **System Services:** Services like networking, printing, and system monitoring consume memory.\\n*   **User Profile:** The user’s desktop environment and applications also consume memory.\\n\\n**Tools for Monitoring:**\\n\\n*   **`top`:** Shows real-time process and memory usage.\\n*   **`htop`:** An enhanced version of `top` that provides more detailed information.\\n*   **`free`:** Displays available, used, and cached memory.\\n*   **`vmstat`:** Provides system-level statistics, including memory usage.\\n*   **`ps`:** Shows process information, including memory usage.\\n\\n**Linux Specific Considerations:**\\n\\n*   **Swap Space:**  The amount of swap space significantly impacts memory usage. More swap can delay usage of RAM,\\n*   **Kernel Memory Management:** Linux has sophisticated memory management, but it can still become a bottleneck if not configured properly.\\n*   **`VGTRAN`:** This is the mechanism Linux uses to manage memory between the kernel and the system, and it has a significant impact on overall memory usage.\\n\\n**It's important to note:**  Memory usage is often not a straightforward number. It’s often better to consider the *pattern* of usage – for example, spikes in memory usage might indicate a problem.\\n\\nIn short, it’s a balance between using *less* memory and ensuring there’s enough available to handle all your workloads efficiently.\"\n",
      "\n",
      "}\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "88bf0518a6b7a1dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
